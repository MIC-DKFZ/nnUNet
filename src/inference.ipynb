{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perform_everything_on_device=True is only supported for cuda devices! Setting this to False\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m model_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/yuma/Yuma-Kanematsu/nnUNet/src/results/Dataset002_ForTest_segmenetation/nnUNetTrainer__nnUNetPlans__2d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# initializes the network architecture, loads the checkpoint\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_from_trained_model_folder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcheckpoint_best.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# variant 1: give input and output folders\u001b[39;00m\n\u001b[1;32m     26\u001b[0m input_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/yuma/Yuma-Kanematsu/nnUNet/src/raw_data/Dataset002_ForTest_segmenetation/imagesTs\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/Yuma-Kanematsu/nnUNet/src/nnunetv2/inference/predict_from_raw_data.py:98\u001b[0m, in \u001b[0;36mnnUNetPredictor.initialize_from_trained_model_folder\u001b[0;34m(self, model_training_output_dir, use_folds, checkpoint_name)\u001b[0m\n\u001b[1;32m     96\u001b[0m configuration_manager \u001b[38;5;241m=\u001b[39m plans_manager\u001b[38;5;241m.\u001b[39mget_configuration(configuration_name)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# restore network\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m num_input_channels \u001b[38;5;241m=\u001b[39m \u001b[43mdetermine_num_input_channels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplans_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfiguration_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m trainer_class \u001b[38;5;241m=\u001b[39m recursive_find_python_class(join(nnunetv2\u001b[38;5;241m.\u001b[39m__path__[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnnUNetTrainer\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    100\u001b[0m                                             trainer_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnnunetv2.training.nnUNetTrainer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Yuma-Kanematsu/nnUNet/src/nnunetv2/utilities/label_handling/label_handling.py:302\u001b[0m, in \u001b[0;36mdetermine_num_input_channels\u001b[0;34m(plans_manager, configuration_or_config_manager, dataset_json)\u001b[0m\n",
      "File \u001b[0;32m~/Yuma-Kanematsu/nnUNet/src/nnunetv2/utilities/plans_handling/plans_handler.py:316\u001b[0m, in \u001b[0;36mget_label_manager\u001b[0;34m(self, dataset_json, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from batchgenerators.utilities.file_and_folder_operations import join\n",
    "from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor\n",
    "\n",
    "# instantiate the nnUNetPredictor\n",
    "predictor = nnUNetPredictor(\n",
    "    tile_step_size=0.5,\n",
    "    use_gaussian=True,\n",
    "    use_mirroring=True,\n",
    "    perform_everything_on_device=True,\n",
    "    device=torch.device('mps', 0),\n",
    "    verbose=False,\n",
    "    verbose_preprocessing=False,\n",
    "    allow_tqdm=True\n",
    ")\n",
    "\n",
    "model_folder = '/Users/yuma/Yuma-Kanematsu/nnUNet/src/results/Dataset002_ForTest_segmenetation/nnUNetTrainer__nnUNetPlans__2d'\n",
    "\n",
    "# initializes the network architecture, loads the checkpoint\n",
    "predictor.initialize_from_trained_model_folder(\n",
    "    model_folder,\n",
    "    use_folds=(0,),\n",
    "    checkpoint_name='checkpoint_best.pth',\n",
    ")\n",
    "# variant 1: give input and output folders\n",
    "input_folder = '/Users/yuma/Yuma-Kanematsu/nnUNet/src/raw_data/Dataset002_ForTest_segmenetation/imagesTs'\n",
    "output_folder = '/Users/yuma/Yuma-Kanematsu/nnUNet/src/results/250328_inferece'\n",
    "predictor.predict_from_files(input_folder,\n",
    "                                output_folder,\n",
    "                                save_probabilities=False, overwrite=True,\n",
    "                                num_processes_preprocessing=2, num_processes_segmentation_export=2,\n",
    "                                folder_with_segs_from_prev_stage=None, num_parts=1, part_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from psd_tools import PSDImage\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "# Paths\n",
    "original_image_path = '/Users/yuma/Yuma-Kanematsu/nnUNet/src/raw_data/Dataset002_ForTest_segmenetation/imagesTs/6870292_16_R_FLOOR-2_0000.png'\n",
    "predicted_mask_path = '/Users/yuma/Yuma-Kanematsu/nnUNet/src/results/250328_inferece/6870292_16_R_FLOOR-2.png'\n",
    "ground_truth_psd_path = '/Users/yuma/Yuma-Kanematsu/nnUNet/src/raw_data/250328_for_test/6870292_16_R_FLOOR-2.psd'\n",
    "output_path = '/Users/yuma/Yuma-Kanematsu/nnUNet/src/raw_data/four_panel_visualization.png'\n",
    "\n",
    "# Parameters\n",
    "color_threshold = 50  # Threshold for red channel extraction from PSD\n",
    "\n",
    "# Function to convert PSD to red mask (from your code)\n",
    "def convert_psd_to_red_mask(psd_path, color_threshold=50):\n",
    "    \"\"\"\n",
    "    Convert PSD file to a binary mask based on red channel\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open PSD file\n",
    "        psd = PSDImage.open(psd_path)\n",
    "        # Get composite image\n",
    "        composite_image = psd.composite()\n",
    "        # Convert to numpy array\n",
    "        img_array = np.array(composite_image)\n",
    "        \n",
    "        # Extract red channel from RGBA array\n",
    "        if len(img_array.shape) == 3 and img_array.shape[2] == 4:  # RGBA\n",
    "            red_channel = img_array[:, :, 0]\n",
    "            green_channel = img_array[:, :, 1]\n",
    "            blue_channel = img_array[:, :, 2]\n",
    "            alpha_channel = img_array[:, :, 3]\n",
    "            \n",
    "            # Red mask condition: high red component, low green and blue, has transparency\n",
    "            red_mask = ((red_channel > green_channel + color_threshold) & \n",
    "                        (red_channel > blue_channel + color_threshold) & \n",
    "                        (alpha_channel > 0))\n",
    "        elif len(img_array.shape) == 3 and img_array.shape[2] == 3:  # RGB\n",
    "            red_channel = img_array[:, :, 0]\n",
    "            green_channel = img_array[:, :, 1]\n",
    "            blue_channel = img_array[:, :, 2]\n",
    "            \n",
    "            # Red mask condition\n",
    "            red_mask = ((red_channel > green_channel + color_threshold) & \n",
    "                        (red_channel > blue_channel + color_threshold))\n",
    "        else:\n",
    "            # Grayscale or unsupported format\n",
    "            print(f\"Warning: Unsupported image format (shape: {img_array.shape})\")\n",
    "            return None\n",
    "        \n",
    "        # Convert to binary mask (True = 1, False = 0) - in nnU-Net, 1 is typically foreground\n",
    "        binary_mask = red_mask.astype(np.uint8)\n",
    "        \n",
    "        return binary_mask\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Processing PSD file {psd_path} failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Check if all files exist\n",
    "files_exist = True\n",
    "for path in [original_image_path, predicted_mask_path, ground_truth_psd_path]:\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Error: File not found: {path}\")\n",
    "        files_exist = False\n",
    "\n",
    "if not files_exist:\n",
    "    print(\"Missing required files. Cannot proceed.\")\n",
    "else:\n",
    "    try:\n",
    "        # Load original image\n",
    "        original_img = Image.open(original_image_path)\n",
    "        original_array = np.array(original_img)\n",
    "        \n",
    "        # Load predicted mask\n",
    "        predicted_mask_img = Image.open(predicted_mask_path)\n",
    "        predicted_mask_array = np.array(predicted_mask_img)\n",
    "        \n",
    "        # Create binary mask from prediction (values > 0 become 255)\n",
    "        binary_predicted_mask = np.zeros_like(predicted_mask_array)\n",
    "        binary_predicted_mask[predicted_mask_array > 0] = 255\n",
    "        \n",
    "        # Process ground truth from PSD\n",
    "        ground_truth_mask = convert_psd_to_red_mask(ground_truth_psd_path, color_threshold)\n",
    "        \n",
    "        # If ground truth mask extraction failed, create empty mask\n",
    "        if ground_truth_mask is None:\n",
    "            print(\"Warning: Could not extract mask from PSD. Creating empty mask.\")\n",
    "            ground_truth_mask = np.zeros_like(binary_predicted_mask)\n",
    "        \n",
    "        # Scale ground truth mask to 0-255 for display\n",
    "        ground_truth_display = ground_truth_mask * 255\n",
    "        \n",
    "        # Display information\n",
    "        print(f\"Original image shape: {original_array.shape}\")\n",
    "        print(f\"Predicted mask shape: {predicted_mask_array.shape}\")\n",
    "        print(f\"Predicted mask range: {predicted_mask_array.min()} to {predicted_mask_array.max()}\")\n",
    "        print(f\"Predicted mask unique values: {np.unique(predicted_mask_array)}\")\n",
    "        print(f\"Ground truth mask shape: {ground_truth_mask.shape}\")\n",
    "        print(f\"Ground truth mask unique values: {np.unique(ground_truth_mask)}\")\n",
    "        \n",
    "        # Create overlay image (original + predicted mask)\n",
    "        # Convert original to RGB if grayscale\n",
    "        if len(original_array.shape) == 2:\n",
    "            original_rgb = np.stack([original_array, original_array, original_array], axis=2)\n",
    "        else:\n",
    "            original_rgb = original_array\n",
    "            \n",
    "        # Create a copy for overlay\n",
    "        overlay_img = original_rgb.copy()\n",
    "        \n",
    "        # Apply red mask for predicted areas\n",
    "        overlay_img[binary_predicted_mask > 0, 0] = 255  # Red channel\n",
    "        overlay_img[binary_predicted_mask > 0, 1] = 0    # Green channel\n",
    "        overlay_img[binary_predicted_mask > 0, 2] = 0    # Blue channel\n",
    "        \n",
    "        # Create the plot (2x2 grid)\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        \n",
    "        # Ground Truth Mask\n",
    "        axes[0, 0].imshow(ground_truth_display, cmap='gray')\n",
    "        axes[0, 0].set_title('Ground Truth')\n",
    "        axes[0, 0].axis('off')\n",
    "        \n",
    "        # Predicted Mask\n",
    "        axes[0, 1].imshow(binary_predicted_mask, cmap='gray')\n",
    "        axes[0, 1].set_title('Predicted Mask')\n",
    "        axes[0, 1].axis('off')\n",
    "        \n",
    "        # Original Image\n",
    "        axes[1, 0].imshow(original_array, cmap='gray' if len(original_array.shape) == 2 else None)\n",
    "        axes[1, 0].set_title('Original Image')\n",
    "        axes[1, 0].axis('off')\n",
    "        \n",
    "        # Overlay (Original + Predicted Mask)\n",
    "        axes[1, 1].imshow(overlay_img)\n",
    "        axes[1, 1].set_title('Original with Predicted Mask')\n",
    "        axes[1, 1].axis('off')\n",
    "        \n",
    "        # Adjust layout and save\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Visualization saved to: {output_path}\")\n",
    "        \n",
    "        # Display in IPython if possible\n",
    "        try:\n",
    "            from IPython.display import display, Image as IPImage\n",
    "            display(IPImage(output_path))\n",
    "        except ImportError:\n",
    "            print(\"IPython display not available. Please check the saved image file.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during visualization: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
